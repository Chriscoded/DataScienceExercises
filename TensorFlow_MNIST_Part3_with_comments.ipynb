{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network for MNIST Classification\n",
    "\n",
    "We'll apply all the knowledge from the lectures in this section to write a deep neural network. The problem we've chosen is referred to as the \"Hello World\" of deep learning because for most students it is the first deep learning algorithm they see.\n",
    "\n",
    "The dataset is called MNIST and refers to handwritten digit recognition. You can find more about it on Yann LeCun's website (Director of AI Research, Facebook). He is one of the pioneers of what we've been talking about and of more complex approaches that are widely used today, such as covolutional neural networks (CNNs). \n",
    "\n",
    "The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image). \n",
    "\n",
    "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes. \n",
    "\n",
    "Our goal would be to build a neural network with 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# TensorFLow includes a data provider for MNIST that we'll use.\n",
    "# It comes with the tensorflow-datasets module, therefore, if you haven't please install the package using\n",
    "# pip install tensorflow-datasets \n",
    "# or\n",
    "# conda install tensorflow-datasets\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# these datasets will be stored in C:\\Users\\*USERNAME*\\tensorflow_datasets\\...\n",
    "# the first time you download a dataset, it is stored in the respective folder \n",
    "# every other time, it is automatically loading the copy on your computer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "That's where we load and preprocess our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/3 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[AWARNING:urllib3.connectionpool:Retrying (Retry(total=9, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F0CC3B90>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]WARNING:urllib3.connectionpool:Retrying (Retry(total=9, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F0CD0550>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-images-idx3-ubyte.gz\n",
      "\u001b[A\u001b[AWARNING:urllib3.connectionpool:Retrying (Retry(total=9, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F0CD0F10>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=9, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5EE46CE10>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=8, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F0CA6990>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=8, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F0CD2B50>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=8, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F0CD3490>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=8, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F0CA63D0>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=7, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F0CD1F10>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=7, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F0CA4610>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=7, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F0CDEFD0>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=7, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F0CDFB90>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F10601D0>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F1060710>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F10612D0>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F1061BD0>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=5, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F1062250>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=5, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F1062790>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=5, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F1063550>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=5, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F1063F10>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F1064610>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F1064E50>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F10656D0>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F1066190>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F10666D0>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F1067110>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F1067910>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F106C410>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Dl Completed...:   0%|                                                                         | 0/4 [00:28<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:28, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/4 [00:28<?, ? url/s]\n",
      "Dl Size...:   0%|                                                                              | 0/9 [00:28<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/4 [00:28<?, ? url/s]\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:28<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:28<01:26, 28.90s/ url]\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:28<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:29<01:26, 28.90s/ url]\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:29<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|                                                                | 0/1 [00:29<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:29<01:26, 28.90s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:29<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 1/1 [00:29<00:00, 29.47s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:35<01:26, 28.90s/ url]\u001b[A\n",
      "Dl Size...:  10%|██████▉                                                              | 1/10 [00:35<05:18, 35.37s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:35<01:26, 28.90s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|█████████████▊                                                       | 2/10 [00:35<04:42, 35.37s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:38<00:34, 17.29s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|█████████████▊                                                       | 2/10 [00:38<04:42, 35.37s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:38<00:34, 17.29s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|█████████████▊                                                       | 2/10 [00:38<04:42, 35.37s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...:  50%|████████████████████████████                            | 1/2 [00:38<00:29, 29.47s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:38<00:34, 17.29s/ url]\u001b[A\n",
      "Dl Size...:  30%|████████████████████▋                                                | 3/10 [00:38<01:11, 10.27s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...:  50%|████████████████████████████                            | 1/2 [00:38<00:29, 29.47s/ file]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:38<00:34, 17.29s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:  30%|████████████████████▋                                                | 3/10 [00:38<01:11, 10.27s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 2/2 [00:38<00:00, 17.40s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:40<00:34, 17.29s/ url]\u001b[A\n",
      "Dl Size...:  40%|███████████████████████████▌                                         | 4/10 [00:40<00:44,  7.42s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 2/2 [00:40<00:00, 17.40s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:42<00:34, 17.29s/ url]\u001b[A\n",
      "Dl Size...:  50%|██████████████████████████████████▌                                  | 5/10 [00:42<00:27,  5.53s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 2/2 [00:42<00:00, 17.40s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:43<00:34, 17.29s/ url]\u001b[A\n",
      "Dl Size...:  60%|█████████████████████████████████████████▍                           | 6/10 [00:43<00:17,  4.31s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 2/2 [00:43<00:00, 17.40s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:45<00:34, 17.29s/ url]\u001b[A\n",
      "Dl Size...:  70%|████████████████████████████████████████████████▎                    | 7/10 [00:45<00:10,  3.55s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 2/2 [00:45<00:00, 17.40s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:47<00:34, 17.29s/ url]\u001b[A\n",
      "Dl Size...:  80%|███████████████████████████████████████████████████████▏             | 8/10 [00:47<00:05,  2.99s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 2/2 [00:47<00:00, 17.40s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:49<00:34, 17.29s/ url]\u001b[A\n",
      "Dl Size...:  90%|██████████████████████████████████████████████████████████████       | 9/10 [00:49<00:02,  2.59s/ MiB]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 2/2 [00:49<00:00, 17.40s/ file]\u001b[A\u001b[AWARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A5F106C750>: Failed to resolve 'storage.googleapis.com' ([Errno 11001] getaddrinfo failed)\")': /cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:51<00:34, 17.29s/ url]\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:51<00:00,  2.43s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:52<00:34, 17.29s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:52<00:00,  2.43s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:52<00:16, 16.07s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:52<00:00,  2.43s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:52<00:16, 16.07s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:52<00:00,  2.43s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [00:53<00:00, 16.07s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:53<00:00,  2.43s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...:  67%|█████████████████████████████████████▎                  | 2/3 [00:53<00:17, 17.40s/ file]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [00:53<00:00, 16.07s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:53<00:00,  2.43s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [00:53<00:00, 16.07s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [01:01<00:00,  2.43s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...:  75%|██████████████████████████████████████████              | 3/4 [01:01<00:16, 16.26s/ file]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [01:03<00:00, 16.07s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [01:03<00:00,  2.43s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 4/4 [01:03<00:00, 15.76s/ file]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [01:03<00:00,  6.31s/ MiB]\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [01:03<00:00, 15.77s/ url]\n",
      "Generating splits...:   0%|                                                                 | 0/2 [00:00<?, ? splits/s]\n",
      "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating train examples...: 1 examples [00:10, 10.14s/ examples]\u001b[A\n",
      "Generating train examples...: 1547 examples [00:11, 190.94 examples/s]\u001b[A\n",
      "Generating train examples...: 3209 examples [00:12, 411.42 examples/s]\u001b[A\n",
      "Generating train examples...: 5142 examples [00:13, 679.55 examples/s]\u001b[A\n",
      "Generating train examples...: 6900 examples [00:14, 891.51 examples/s]\u001b[A\n",
      "Generating train examples...: 8899 examples [00:15, 1137.68 examples/s]\u001b[A\n",
      "Generating train examples...: 10732 examples [00:16, 1286.97 examples/s]\u001b[A\n",
      "Generating train examples...: 12616 examples [00:17, 1438.23 examples/s]\u001b[A\n",
      "Generating train examples...: 14574 examples [00:18, 1576.22 examples/s]\u001b[A\n",
      "Generating train examples...: 16442 examples [00:19, 1654.32 examples/s]\u001b[A\n",
      "Generating train examples...: 18353 examples [00:20, 1726.23 examples/s]\u001b[A\n",
      "Generating train examples...: 20232 examples [00:21, 1745.53 examples/s]\u001b[A\n",
      "Generating train examples...: 22084 examples [00:22, 1766.50 examples/s]\u001b[A\n",
      "Generating train examples...: 23926 examples [00:23, 1771.42 examples/s]\u001b[A\n",
      "Generating train examples...: 25750 examples [00:24, 1778.97 examples/s]\u001b[A\n",
      "Generating train examples...: 27642 examples [00:25, 1811.76 examples/s]\u001b[A\n",
      "Generating train examples...: 29481 examples [00:26, 1779.41 examples/s]\u001b[A\n",
      "Generating train examples...: 31373 examples [00:27, 1812.17 examples/s]\u001b[A\n",
      "Generating train examples...: 33200 examples [00:28, 1813.86 examples/s]\u001b[A\n",
      "Generating train examples...: 35133 examples [00:29, 1849.07 examples/s]\u001b[A\n",
      "Generating train examples...: 36990 examples [00:30, 1723.47 examples/s]\u001b[A\n",
      "Generating train examples...: 38736 examples [00:31, 1698.23 examples/s]\u001b[A\n",
      "Generating train examples...: 40811 examples [00:32, 1805.14 examples/s]\u001b[A\n",
      "Generating train examples...: 42633 examples [00:33, 1798.51 examples/s]\u001b[A\n",
      "Generating train examples...: 44479 examples [00:34, 1812.29 examples/s]\u001b[A\n",
      "Generating train examples...: 46300 examples [00:35, 1757.60 examples/s]\u001b[A\n",
      "Generating train examples...: 48067 examples [00:36, 1717.17 examples/s]\u001b[A\n",
      "Generating train examples...: 49830 examples [00:37, 1729.33 examples/s]\u001b[A\n",
      "Generating train examples...: 51565 examples [00:39, 1701.32 examples/s]\u001b[A\n",
      "Generating train examples...: 53271 examples [00:40, 1695.77 examples/s]\u001b[A\n",
      "Generating train examples...: 54970 examples [00:41, 1651.40 examples/s]\u001b[A\n",
      "Generating train examples...: 56625 examples [00:42, 1606.04 examples/s]\u001b[A\n",
      "Generating train examples...: 58235 examples [00:43, 1515.44 examples/s]\u001b[A\n",
      "Generating train examples...: 59761 examples [00:44, 1501.64 examples/s]\u001b[A\n",
      "                                                                        \u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:   0%| | 0/6000\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:   0%| | 1/6000\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:   4%| | 2252/6\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:   8%| | 4828/6\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  12%| | 7009/6\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  16%|▏| 9513/6\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  19%|▏| 11690/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  23%|▏| 13734/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  26%|▎| 15765/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  30%|▎| 17771/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  34%|▎| 20141/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  37%|▎| 22349/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  41%|▍| 24464/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  44%|▍| 26434/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  47%|▍| 28393/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  51%|▌| 30340/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  54%|▌| 32276/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  58%|▌| 34575/\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  62%|▌| 37077/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  66%|▋| 39596/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  70%|▋| 41839/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  73%|▋| 43965/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  77%|▊| 46414/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  81%|▊| 48599/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  85%|▊| 51030/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  89%|▉| 53275/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  92%|▉| 55476/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...:  96%|▉| 57581/\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-train.tfrecord*...: 100%|▉| 59953/\u001b[A\n",
      "Generating splits...:  50%|████████████████████████████▌                            | 1/2 [00:51<00:51, 51.03s/ splits]\u001b[A\n",
      "Generating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating test examples...: 1634 examples [00:01, 1632.38 examples/s]\u001b[A\n",
      "Generating test examples...: 3639 examples [00:02, 1851.48 examples/s]\u001b[A\n",
      "Generating test examples...: 5788 examples [00:03, 1987.18 examples/s]\u001b[A\n",
      "Generating test examples...: 7776 examples [00:04, 1986.78 examples/s]\u001b[A\n",
      "Generating test examples...: 9763 examples [00:05, 1824.38 examples/s]\u001b[A\n",
      "                                                                      \u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-test.tfrecord*...:   0%| | 0/10000\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-test.tfrecord*...:  20%|▏| 2042/10\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-test.tfrecord*...:  46%|▍| 4635/10\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-test.tfrecord*...:  70%|▋| 7031/10\u001b[A\n",
      "Shuffling C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1.incomplete5PSXIN\\mnist-test.tfrecord*...:  95%|▉| 9519/10\u001b[A\n",
      "                                                                                                                       \u001b[A\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\CHRISCODED\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# remember the comment from above\n",
    "# these datasets will be stored in C:\\Users\\*USERNAME*\\tensorflow_datasets\\...\n",
    "# the first time you download a dataset, it is stored in the respective folder \n",
    "# every other time, it is automatically loading the copy on your computer \n",
    "\n",
    "# tfds.load actually loads a dataset (or downloads and then loads if that's the first time you use it) \n",
    "# in our case, we are interesteed in the MNIST; the name of the dataset is the only mandatory argument\n",
    "# there are other arguments we can specify, which we can find useful\n",
    "# mnist_dataset = tfds.load(name='mnist', as_supervised=True)\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "# with_info=True will also provide us with a tuple containing information about the version, features, number of samples\n",
    "# we will use this information a bit below and we will store it in mnist_info\n",
    "\n",
    "# as_supervised=True will load the dataset in a 2-tuple structure (input, target) \n",
    "# alternatively, as_supervised=False, would return a dictionary\n",
    "# obviously we prefer to have our inputs and targets separated \n",
    "\n",
    "# once we have loaded the dataset, we can easily extract the training and testing dataset with the built references\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "\n",
    "# by default, TF has training and testing datasets, but no validation sets\n",
    "# thus we must split it on our own\n",
    "\n",
    "# we start by defining the number of validation samples as a % of the train samples\n",
    "# this is also where we make use of mnist_info (we don't have to count the observations)\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "# let's cast this number to an integer, as a float may cause an error along the way\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "# let's also store the number of test samples in a dedicated variable (instead of using the mnist_info one)\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "# once more, we'd prefer an integer (rather than the default float)\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "\n",
    "# normally, we would like to scale our data in some way to make the result more numerically stable\n",
    "# in this case we will simply prefer to have inputs between 0 and 1\n",
    "# let's define a function called: scale, that will take an MNIST image and its label\n",
    "def scale(image, label):\n",
    "    # we make sure the value is a float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # since the possible values for the inputs are 0 to 255 (256 different shades of grey)\n",
    "    # if we divide each element by 255, we would get the desired result -> all elements will be between 0 and 1 \n",
    "    image /= 255.\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# the method .map() allows us to apply a custom transformation to a given dataset\n",
    "# we have already decided that we will get the validation data from mnist_train, so \n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "\n",
    "# finally, we scale and batch the test data\n",
    "# we scale it so it has the same magnitude as the train and validation\n",
    "# there is no need to shuffle it, because we won't be training on the test data\n",
    "# there would be a single batch, equal to the size of the test data\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "\n",
    "# let's also shuffle the data\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "# this BUFFER_SIZE parameter is here for cases when we're dealing with enormous datasets\n",
    "# then we can't shuffle the whole dataset in one go because we can't fit it all in memory\n",
    "# so instead TF only stores BUFFER_SIZE samples in memory at a time and shuffles them\n",
    "# if BUFFER_SIZE=1 => no shuffling will actually happen\n",
    "# if BUFFER_SIZE >= num samples => shuffling is uniform\n",
    "# BUFFER_SIZE in between - a computational optimization to approximate uniform shuffling\n",
    "\n",
    "# luckily for us, there is a shuffle method readily available and we just need to specify the buffer size\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "# once we have scaled and shuffled the data, we can proceed to actually extracting the train and validation\n",
    "# our validation data would be equal to 10% of the training set, which we've already calculated\n",
    "# we use the .take() method to take that many samples\n",
    "# finally, we create a batch with a batch size equal to the total number of validation samples\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "\n",
    "# similarly, the train_data is everything else, so we skip as many samples as there are in the validation dataset\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "# determine the batch size\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# we can also take advantage of the occasion to batch the train data\n",
    "# this would be very helpful when we train, as we would be able to iterate over the different batches\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "\n",
    "# batch the test data\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "\n",
    "# takes next batch (it is the only batch)\n",
    "# because as_supervized=True, we've got a 2-tuple structure\n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='mnist',\n",
       "    full_name='mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    The MNIST database of handwritten digits.\n",
       "    \"\"\",\n",
       "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
       "    data_dir='C:\\\\Users\\\\CHRISCODED\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
       "    file_format=tfrecord,\n",
       "    download_size=11.06 MiB,\n",
       "    dataset_size=21.00 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{lecun2010mnist,\n",
       "      title={MNIST handwritten digit database},\n",
       "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
       "      volume={2},\n",
       "      year={2010}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
